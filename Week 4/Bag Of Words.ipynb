{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Bag of Words](Bag-of-Words)\n",
    "\n",
    "1. [Idea Behind Bag of Words](#Idea-Behind-Bag-of-Words)   \n",
    "2. [An Aside on Documents](#An-Aside-on-Documents)    \n",
    "3. [Applying Bag of Words to A Collection of Documents](#Applying-Bag-of-Words-to-A-Collection-of-Documents)    \n",
    "4. [Word Frequency Vectors](Word-Frequency-Vectors)\n",
    "\n",
    "\n",
    "# Bag of Words\n",
    "\n",
    "We'll now put all that data cleaning to work to turn text data into mathematical objects. In particular we'll learn about three different types of vectors we can use to analyze text data, all built upon a concept known as bag of words.\n",
    "\n",
    "##  Idea Behind Bag of Words\n",
    "We've come close to bag of words when we looked at Harry Potter and the Prisoner of Azkaban and Harry Potter and the Goblet of Fire. It's more or less a fancy name for our word count dataframes.\n",
    "\n",
    "The idea behind bag of words is that you take all of the words in your document and put them into a bag. Then you pull the words out and count them up.\n",
    "\n",
    "As we've previously discussed this disregards ordering of words, but the same concept can be applied to -grams to create a bag of -grams model.\n",
    "\n",
    "## An Aside on Documents\n",
    "From now on we'll start referring to an observation (think row in a dataframe) of text data to a document. Colloquially the mention of a document may make you think of a single paper for a college or high school english class, but in the realm of NLP a document is more general. For example, an entire book may be a document, or perhaps just a single sentence or paragraph of the book. Other examples may include text messages, emails, tweets and vaccuum repair manuals.\n",
    "\n",
    "## Applying Bag of Words to A Collection of Documents\n",
    "So far we've made a bag of words vector for a single document, there is a slight difference when workinig with a collection of documents. Let's return to the excerpt from [IMDB Dataset of 50K Movie Reviews](https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews?select=IMDB+Dataset.csv)  `IMDB Dataset.csv`.   \n",
    "\n",
    "I have reduced it into a smaller one called `Movie_Review.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# we'll use this for the spam messages\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv('Movie_Review.csv')\n",
    "df = pd.read_csv('IMDB Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 - Turn Negative/Positive into 0/1\n",
    "\n",
    "Turn the label 'Negative' or 'Positive' into a 0 or a 1. Here 0 should mean the review was 'Negative', while a 1 should mean the review was 'Positive\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.sentiment == \"positive\",'coding'] = 1\n",
    "df.loc[df.sentiment == \"negative\",'coding'] = 0\n",
    "\n",
    "df_train = df.sample(frac=.8,random_state = 123).copy()\n",
    "df_test = df.drop(df_train.index).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look into making a word count vector for the first two messages in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define functions\n",
    "# make the tokenizer object\n",
    "tokenizer = TweetTokenizer()\n",
    "\n",
    "# make word counts\n",
    "def get_word_counts(tokens):\n",
    "    word_dict = {}\n",
    "    \n",
    "    for word in tokens:\n",
    "        if word in word_dict.keys():\n",
    "            word_dict[word] = word_dict[word] + 1\n",
    "        else:\n",
    "            word_dict[word] = 1\n",
    "            \n",
    "    return pd.DataFrame({'word': word_dict.keys(),\n",
    "                            'times_counted': word_dict.values()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get tokens\n",
    "df_train['review_lower'] = df_train.review.str.lower()\n",
    "df_train['tokens'] = df_train['review_lower'].apply(tokenizer.tokenize)\n",
    "\n",
    "## get the first two reviews\n",
    "rev_tokens_1 = list(df_train.tokens.values)[0]\n",
    "rev_tokens_2 = list(df_train.tokens.values)[1]\n",
    "\n",
    "print(\"message 1\")\n",
    "print(get_word_counts(rev_tokens_1))\n",
    "\n",
    "print()\n",
    "print()\n",
    "\n",
    "print(\"message 2\")\n",
    "print(get_word_counts(rev_tokens_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How would we compare these two vectors? They are two completely different dimensions and are not in vector spaces spanned by the same basis.\n",
    "\n",
    "This is where the subtle difference comes into play. When making a bag of words vector model of the documents we first need to collect all of the unique words that occur accross all documents of the corpus (collection of documents). These unique words then correspond to a basis vector in the bag of words vector space.\n",
    "\n",
    "Let's look at the first two messages bag of word vectors.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will take in a dataframe of \"words\" (note ngrams will work as well)\n",
    "# and return a list of the unique words, which forms the basis\n",
    "def get_bow_basis(df,column_name):\n",
    "    basis_set = []\n",
    "    \n",
    "    for i in df.index:\n",
    "        for word in df[column_name][i]:\n",
    "            basis_set.append(word)\n",
    "            \n",
    "    return np.array(list(set(basis_set)))\n",
    "\n",
    "## This will take in a basis set and a message's tokens\n",
    "## and return the bow numpy array (vector)\n",
    "def get_bow_vector(tokens, basis_set):\n",
    "    vector = np.zeros(len(basis_set))\n",
    "    \n",
    "    for word in tokens:\n",
    "        # Note this is here for when we look at the test set\n",
    "        if word in basis_set:\n",
    "            vector[basis_set == word] = vector[basis_set == word] + 1\n",
    "        \n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basis_set = get_bow_basis(df_train,'tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basis_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"review 1\", get_bow_vector(rev_tokens_1, basis_set))\n",
    "print()\n",
    "print(\"review 2\", get_bow_vector(rev_tokens_2, basis_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You Code\n",
    "Make a np.array that records the bow vector for each of the documents in the training set. Each row of the array should represent a document, and each column one of the entries of the basis set. Note this sort of matrix is called a document-term matrix.\n",
    "\n",
    "Call your array `doc_term_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More Coding By You\n",
    "How many columns are there in your document-term matrix?\n",
    "\n",
    "If you wanted to do a Sentiment identification process we'd probably want to reduce the dimensionality of this data set. Use `sklearn`'s PCA to produce an explained variance ratio curve following the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here\n",
    "# (rows,columns)\n",
    "np.shape(doc_term_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import pca and matplotlib.pyplot\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from seaborn import set_style\n",
    "\n",
    "set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a pipeline that scales the data and then\n",
    "# applies pca\n",
    "pca_pipe = Pipeline([('scale',StandardScaler()),\n",
    "                         ('pca',PCA())])\n",
    "\n",
    "# This fits the pipeline\n",
    "pca_pipe.fit(doc_term_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a figure\n",
    "plt.figure(figsize=(10,8))\n",
    "\n",
    "# plot the number of components on the x\n",
    "# plot the explained variance ratio on the y\n",
    "plt.plot(range(1, len(pca_pipe['pca'].explained_variance_ratio_)+1),\n",
    "            np.cumsum(pca_pipe['pca'].explained_variance_ratio_))\n",
    "\n",
    "plt.xlabel(\"Number of Components\",fontsize=14)\n",
    "plt.ylabel(\"Cumulative Explained Variance\",fontsize=14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Even More Coding By You\n",
    "Let's use this PCA to build an `SVC` classifier. \n",
    "\n",
    "__Note:__ that you don't need to know what the support vector classifier does to follow along with this code chunk. Just know that it is a very powerful classification algorithm, and you can always fill in the details later. After you've fit the classifier find the training true positive rate and the training false positive rate.\n",
    "\n",
    "We'll use the first `1500` components of the PCA fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will give you the data projected onto\n",
    "# the first 1500 PCA dimensions\n",
    "fit = pca_pipe.transform(doc_term_train)[:,:1500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You define the functions to calculate True Positive Rate\n",
    "# and False positive rate here\n",
    "def tpr(actual,pred):\n",
    "\n",
    "    \n",
    "def fpr(actual,pred):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Support Vector Classifier is stored\n",
    "# in sklearn.svm\n",
    "from sklearn.svm import SVC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a classifier object\n",
    "svc = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this fits the object on the training data\n",
    "svc.fit(fit, df_train.coding.values)\n",
    "\n",
    "# this produces the classifiers prediction on\n",
    "# that data\n",
    "pred = svc.predict(fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out the tpr and fpr here\n",
    "print(\"Training tpr =\",tpr(df_train.coding.values, pred))\n",
    "print(\"Training fpr =\",fpr(df_train.coding.values, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Frequency Vectors\n",
    "For a number of reasons that you may have already guessed (and potentially asked me about), bag of words vectors may not always be the best kind of vector for your application. A nice example from Natural Language Processing in Action is the following.\n",
    "\n",
    "If I tell you that document A contains the word \"dog\" 3 times, and document B contains the word \"dog\" 100 times you may be inclinded to think that document B is more likely to be about dogs that document A. However, the sharp thinker (which I know all of you are!) would realize that the length of the documents is relavent here. In this example document A was a short email (30 words) about scheduling a vet appointment, while document B was the incredibly long novel War and Peace (580000 words). Thus dog is 1/10 of document A while dog is 0.00017 of document B.\n",
    "\n",
    "This sort of example highlights the need for a term frequency vector. A term frequency vector takes the bag of words vector we previously discussed and divides each entry by the number of terms in the document. For example, if you had the following bag of words vector:\n",
    "\n",
    "$$\n",
    "(0,0,1,2,1)\n",
    "$$\n",
    "you'd end up with this frequency vector:\n",
    "$$\n",
    "(0,0,1/4,1/2,1/4)\n",
    "$$\n",
    "\n",
    "### You Code\n",
    "Turn your document-term matrix from a bag of words matrix to a frequency matrix, call the matrix doc_term_train_freq.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You Code Some More\n",
    "Now run this data through PCA and plot the explained variance curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we make a new pipeline for this second model\n",
    "pca_pipe_freq = Pipeline([('scale',StandardScaler()),\n",
    "                             ('pca',PCA())])\n",
    "\n",
    "pca_pipe_freq.fit(doc_term_train_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "\n",
    "\n",
    "# Below we again plot the explained variance. \n",
    "# note this plot should look identical to the previous one because \n",
    "plt.plot(range(1, len(pca_pipe_freq['pca'].explained_variance_ratio_)+1),\n",
    "            np.cumsum(pca_pipe_freq['pca'].explained_variance_ratio_))\n",
    "\n",
    "plt.xlabel(\"Number of Components\",fontsize=14)\n",
    "plt.ylabel(\"Cumulative Explained Variance\",fontsize=14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You Code Even More\n",
    "Fit the classifier on the frequency matrix projected onto the first 1500 PCA dimensions, calculate the training tpr and fpr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_freq = pca_pipe_freq.transform(doc_term_train_freq)[:,:1500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_freq = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this fits the object on the training data\n",
    "svc_freq.fit(fit_freq, df_train.coding.values)\n",
    "\n",
    "# this produces the classifiers prediction on\n",
    "# that data\n",
    "pred_freq = svc_freq.predict(fit_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You print out the training tpr and fpr here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The TLDR of TF-IDF (still probably a little long though!)\n",
    "The final document vector type we'll discuss in this notebook is the TF-IDF vector. The TF of TF-IDF stands for term frequency, this is the vector type that we just finished working with. So let's introduce the IDF.\n",
    "\n",
    "IDF stands for inverse document frequency. The document frequency of a given term is the number of documents that contain that term. For example if your corpus has 10 documents and 3 of them use the word \"cat\", then the document frequency for \"cat\" is 3/10. The inverse document frequency of \"cat\" in this example is the inverse of that, so 10/3.\n",
    "\n",
    "To compute the tf-idf of a term for a given document you multiply the term frequency of the term within that document by the  (base 10) of the inverse document frequency for that term across the corpus.\n",
    "\n",
    "Returning to our cat example. Let's suppose the word \"cat\" occurs 2 times in a document that has 12 words, and this document is a part of the 10 document corpus we mentioned a few seconds ago. Then the entry for \"cat\" in this document's tfidf vector is:\n",
    " \n",
    "$$\n",
    "\\mbox{tfidf = term-frequency} \\times \\log (\\mbox{inverse-document-frequency}) = \\frac{2}{12}\\log\\left(\\frac{10}{3}\\right)\n",
    "$$\n",
    " \n",
    "\n",
    "I'm guessing you have two questions at this point.\n",
    "\n",
    "### 1. Why the  $\\log $?\n",
    "I haven't found a satisfactory answer to this yet, but this stackexchange post https://math.stackexchange.com/questions/1362323/why-do-use-logarithms-in-the-tf-idf-formula gives a couple of explanations. One is related to Zipf's law (more on that in notebook 2). The other is that the tf-idf approach stems from the field of information theory and is related to something called entropy which involves the $\\log $.\n",
    "\n",
    "### 2. Why is this useful?\n",
    "It's a reasonable question. Once reason this may be useful is because it kind of filters out common terms (What's the idf for a term that appears in every document?) and highlights terms that seldomly appear accross the corpus. This is useful for information retrieval from a corpus of documents all about the same thing. For instance if you have a a collection of documents about cats, and only one of them is about veterinary practices for cats the tf-idf vector for that document would give a heavy weight to terms like veterinarian.\n",
    "\n",
    "### You Code Again\n",
    "Compute the tf-idf matrix for our training data. Will this matrix be useful for classifation? I have no idea, but let's do it anyway. Call this matrix `doc_term_train_tfidf`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You Code More Again\n",
    "Run the tf-idf matrix for the training data through PCA and plot the explained variance ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You Code Even More.. Again!\n",
    "Now project the tfidf matrix onto the first 1500 dimensions and fit the svc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When you're ready print the training TPR and FPR here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### That's It!\n",
    "That's it for this notebook, next up we're going to look at way we can calculate how alike two documents are. Note you can calculate the performance on the test set for homework below. Note to respect the train-test split the bag of words basis set should be the training bag of words basis set. Also when you calculate the tfidf use the idf calculated on the training set only.\n",
    "\n",
    "### Calculate Test Set Performance Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
