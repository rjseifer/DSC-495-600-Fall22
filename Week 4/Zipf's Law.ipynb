{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zipf's Law\n",
    "\n",
    "Zipf's law is based upon an empirical observation about the frequency distribution of the words that occur within a given corpus of documents.\n",
    "\n",
    "We'll explore this on our own, before stating the \"law\" at the end. I'll also provide you a link to a paper that explores this \"law\" in more depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We'll want the following packages\n",
    "\n",
    "# for data handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# for nlp tokenizing\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from seaborn import set_style\n",
    "# puts a white grid behind your plots\n",
    "set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at our Two reviews data sets. The following code is a copy and paste from the NLP Data Folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_df = pd.read_csv('Movie_Review.csv')\n",
    "movie_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_df = pd.read_csv('Food_Review.csv')\n",
    "food_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll keep it as lowercase text for simplicity\n",
    "movie_df['review_lower'] =movie_df.review.str.lower()\n",
    "food_df['text_lower'] = food_df.Text.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_list = movie_df['review_lower'].tolist()\n",
    "raw_text = ''.join(words_list)\n",
    "movie_words = raw_text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_list = food_df['text_lower'].tolist()\n",
    "raw_text = ''.join(words_list)\n",
    "food_words = raw_text.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to tokenize, is using `word_tokenize`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_df['tokens'] = movie_df['review_lower'].apply(word_tokenize)\n",
    "food_df['tokens'] = food_df['text_lower'].apply(word_tokenize) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Turn\n",
    "Okay now you write a function that will take in these tokens and produce a `word` frequency dataframe. The dataframe should contain a word column and a frequency column. Call your dataframes  `Mov_df` and `FOD_df`.\n",
    "\n",
    "It will likely be easiest to write this as a function that you can apply to both token arrays.\n",
    "\n",
    "__Note:__ While this may be confusing, don't create the word frequency vector by creating a bag of words basis set. Every entry in your vector should be . Please ask for clarification if this note was confusing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Producing Ranks for the Words\n",
    "Now that you have dataframes, run the following code to add a column that ranks the words based on their frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rank documentation\n",
    "# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.rank.html\n",
    "Mov_df['word_rank'] = Mov_df['frequency'].rank(ascending=False)\n",
    "FOD_df['word_rank'] = FOD_df['frequency'].rank(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use `matplotlib`'s `scatter` to plot the -transform rank on the -axis and the -transform frequency on the -axis (both base ). Make the Prisoner of Azkaban points blue and the Goblet of Fire points red, and add a legend.\n",
    "\n",
    "Hint: `np.log10` produces the $\\log$-transform of an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding a Regression Line\n",
    "Now let's add a simple linear regression line to the plot you just produced. Running the code chunks below will give you arrays to add with a `plt.plot()` call. Add this line as a black dotted line with `alpha=.7`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combines the data into a single array for regression\n",
    "x = np.log10(np.array(pd.concat([Mov_df['word_rank'],FOD_df['word_rank']])))\n",
    "y = np.log10(np.array(pd.concat([Mov_df['frequency'],FOD_df['frequency']])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the LinearRegression class from sklearn\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a LinearRegression object\n",
    "slr = LinearRegression()\n",
    "\n",
    "# fit the model\n",
    "slr.fit(x.reshape(-1,1),y.ravel())\n",
    "\n",
    "# These are the x and y for your regression line\n",
    "xs_pred = np.linspace(-.1,5,100)\n",
    "ys_pred = slr.predict(xs_pred.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the two sets of observations tend to fall along a straight line. This is the idea behind Zipf's Law.\n",
    "\n",
    "From Wikipedia Zipf's law states that:\n",
    "\n",
    "_The frequency of any word is inversely proportional to its rank in the frequency table_.\n",
    "\n",
    "In more mathematical words there is the following observed relationship between the word's rank,$r$ , and the frequency,$f(r)$ :\n",
    "\n",
    "$$\n",
    "f(r) \\ \\ \\alpha \\ \\ \\frac{1}{r^{\\alpha}}\n",
    "$$\n",
    " \n",
    "across the documents within a corpus, meaning the frequency of a word roughly follows a power law of its rank.\n",
    "\n",
    "\n",
    "### A Note\n",
    "It's important to note that this is an empirical relationship, not something that has been proven rigorously. As such there are critiques to this that may be interesting to you, https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4176592/. But for the most part it seems that this relationship roughly holds.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
